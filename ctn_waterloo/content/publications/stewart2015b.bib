@article{stewart2015closed,
  title={Closed-Loop Neuromorphic Benchmarks},
  author={Stewart, Terrence C and DeWolf, Travis and Kleinhans, Ashley and Eliasmith, Chris},
  journal={Frontiers in neuroscience},
  volume={9},
  year={2015},
  publisher={Frontiers Media SA},
  abstract = {Evaluating the effectiveness and performance of neuromorphic hardware is difficult. It is even more difficult when the task of interest is a closed-loop task; that is, a task where the output from the neuromorphic hardware affects some environment, which then in turn affects the hardware's future input. However, closed-loop situations are one of the primary potential uses of neuromorphic hardware. To address this, we present a methodology for generating closed-loop benchmarks that makes use of a hybrid of real physical embodiment and a type of “minimal” simulation. Minimal simulation has been shown to lead to robust real-world performance, while still maintaining the practical advantages of simulation, such as making it easy for the same benchmark to be used by many researchers. This method is flexible enough to allow researchers to explicitly modify the benchmarks to identify specific task domains where particular hardware excels. To demonstrate the method, we present a set of novel benchmarks that focus on motor control for an arbitrary system with unknown external forces. Using these benchmarks, we show that an error-driven learning rule can consistently improve motor control performance across a randomly generated family of closed-loop simulations, even when there are up to 15 interacting joints to be controlled.},
  pdf = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4678234/},
}
